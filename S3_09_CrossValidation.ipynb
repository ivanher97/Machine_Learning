{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22054735",
   "metadata": {},
   "source": [
    "# üîÑ Validaci√≥n Cruzada (Cross Validation, CV)\n",
    "\n",
    "La **validaci√≥n cruzada** es una t√©cnica para evaluar el rendimiento de un modelo y ajustar sus hiperpar√°metros de manera m√°s robusta.  \n",
    "Incluso cuando se usa validaci√≥n cruzada, se debe reservar un **conjunto de prueba independiente** para la evaluaci√≥n final.  \n",
    "\n",
    "---\n",
    "\n",
    "## üìå M√©todo Hold-out (Retenci√≥n)\n",
    "\n",
    "### Procedimiento:\n",
    "1. Dividir el conjunto de datos en **entrenamiento** y **prueba**.  \n",
    "2. Usar el conjunto de entrenamiento para entrenar el modelo.  \n",
    "3. Usar el conjunto de prueba para estimar el rendimiento de generalizaci√≥n.  \n",
    "\n",
    "### Variaci√≥n:\n",
    "- Dividir el conjunto de entrenamiento en dos partes:  \n",
    "  - **Entrenamiento** ‚Üí para ajustar distintos modelos.  \n",
    "  - **Validaci√≥n** ‚Üí para comparar configuraciones de par√°metros y seleccionar el mejor modelo.  \n",
    "\n",
    "üëâ Este proceso se conoce como **selecci√≥n de modelo (model selection)**.  \n",
    "Su objetivo es encontrar los **valores √≥ptimos de los hiperpar√°metros**.  \n",
    "\n",
    "---\n",
    "\n",
    "## üìå k-fold Cross Validation (Validaci√≥n cruzada k-fold)\n",
    "\n",
    "### Procedimiento b√°sico:\n",
    "1. Dividir el conjunto de entrenamiento en **k subconjuntos (folds)**, sin reemplazo.  \n",
    "2. Para cada fold:  \n",
    "   - Entrenar el modelo con **k ‚Äì 1 folds**.  \n",
    "   - Evaluar el modelo en el **fold restante**.  \n",
    "3. Repetir el proceso **k veces**, cambiando el fold de evaluaci√≥n en cada iteraci√≥n.  \n",
    "4. Calcular la **puntuaci√≥n final** como el promedio de las k mediciones.  \n",
    "\n",
    "### Resultados:\n",
    "- Se obtienen **k modelos** y **k estimaciones de rendimiento**.  \n",
    "- La media de las puntuaciones es una estimaci√≥n m√°s robusta y menos sensible a c√≥mo se parti√≥ el conjunto de datos (comparado con hold-out).  \n",
    "\n",
    "### Usos:\n",
    "- Ajustar el modelo.  \n",
    "- Seleccionar hiperpar√°metros √≥ptimos.  \n",
    "- Reentrenar el modelo final con **todos los datos de entrenamiento**.  \n",
    "- Evaluar finalmente con el **conjunto de prueba independiente**.  \n",
    "\n",
    "üìå Valor com√∫n: `k = 10`.  \n",
    "- Para conjuntos peque√±os, conviene usar un `k` m√°s alto.  \n",
    "\n",
    "---\n",
    "\n",
    "## üìå Validaci√≥n Cruzada k-fold Estratificada (Stratified k-fold)\n",
    "\n",
    "- Es una **variaci√≥n** de la validaci√≥n cruzada k-fold.  \n",
    "- Asegura que la **proporci√≥n de clases** se mantenga en cada fold.  \n",
    "- Proporciona **mejores estimaciones de sesgo y varianza**, especialmente cuando las clases est√°n **desbalanceadas**.  \n",
    "\n",
    "---\n",
    "\n",
    "## üìä En resumen\n",
    "\n",
    "- **Hold-out** ‚Üí simple y r√°pido, pero depende mucho de c√≥mo se dividen los datos.  \n",
    "- **k-fold CV** ‚Üí m√°s robusto, proporciona un promedio de rendimiento.  \n",
    "- **Stratified k-fold** ‚Üí mejor opci√≥n cuando hay **clases desbalanceadas**.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f405a3f8",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# ILUSTRACION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1819a11e",
   "metadata": {},
   "source": [
    "## Ilustraci√≥n\n",
    "\n",
    "### Validaci√≥n cruzada: evaluando el rendimiento del estimador\n",
    "\n",
    "Adaptado de [scikit learn] (Validaci√≥n cruzada: evaluando el rendimiento del estimador)\n",
    "\n",
    "Aprender los par√°metros de una funci√≥n de predicci√≥n y probarla en los mismos datos es un error metodol√≥gico:  \n",
    "un modelo que simplemente repetir√≠a las etiquetas de las muestras que acaba de ver tendr√≠a una puntuaci√≥n perfecta,  \n",
    "pero fallar√≠a al predecir cualquier cosa en datos a√∫n no vistos.  \n",
    "A esta situaci√≥n se le llama **sobreajuste (overfitting)**.\n",
    "\n",
    "Para evitarlo, es una pr√°ctica com√∫n al realizar un experimento de aprendizaje autom√°tico (supervisado) reservar parte  \n",
    "de los datos disponibles como un **conjunto de prueba** `X_test`, `y_test`.  \n",
    "\n",
    "Nota: la palabra ‚Äúexperimento‚Äù no debe entenderse como de uso acad√©mico exclusivo; incluso en entornos comerciales,  \n",
    "el aprendizaje autom√°tico normalmente comienza de manera experimental.\n",
    "\n",
    "En *scikit-learn*, una divisi√≥n aleatoria en conjuntos de entrenamiento y prueba se puede calcular r√°pidamente con la funci√≥n auxiliar  \n",
    "`train_test_split`. Carguemos el conjunto de datos *iris* para ajustar una m√°quina de vectores de soporte lineal sobre √©l.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c24028e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:14: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:14: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/tmp/ipykernel_5784/4186260902.py:14: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  boston = pd.read_csv(\"/media/sf_MV_COMP/data/housing.data\", sep=\"\\s+\", header = None)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2   3      4      5   ...  8      9     10      11    12    13\n",
       "0  0.00632  18.0  2.31   0  0.538  6.575  ...   1  296.0  15.3  396.90  4.98  24.0\n",
       "1  0.02731   0.0  7.07   0  0.469  6.421  ...   2  242.0  17.8  396.90  9.14  21.6\n",
       "2  0.02729   0.0  7.07   0  0.469  7.185  ...   2  242.0  17.8  392.83  4.03  34.7\n",
       "3  0.03237   0.0  2.18   0  0.458  6.998  ...   3  222.0  18.7  394.63  2.94  33.4\n",
       "4  0.06905   0.0  2.18   0  0.458  7.147  ...   3  222.0  18.7  396.90  5.33  36.2\n",
       "\n",
       "[5 rows x 14 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "\n",
    "# Asi se cargaria un dataset de sns pero boston ya no esta disponible\n",
    "# boston = datasets.load_boston()\n",
    "boston = pd.read_csv(\"/media/sf_MV_COMP/data/housing.data\", sep=\"\\s+\", header = None)\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79921eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65f19a2",
   "metadata": {},
   "source": [
    "## ¬øPor qu√© separar en `X` e `y`?\n",
    "\n",
    "Cuando cargamos el dataset con `pandas.read_csv`, todas las columnas quedan juntas en un **DataFrame**.  \n",
    "Sin embargo, para entrenar un modelo en **scikit-learn** necesitamos **separar**:\n",
    "\n",
    "- `X` ‚Üí las **caracter√≠sticas de entrada** (features), es decir, las columnas que usamos para predecir.  \n",
    "- `y` ‚Üí la **variable objetivo** (target), es decir, la columna que queremos que el modelo aprenda a predecir.  \n",
    "\n",
    "### Ejemplo con el dataset Boston Housing:\n",
    "- `X = boston.iloc[:, :-1]` ‚Üí todas las columnas menos la √∫ltima (informaci√≥n de las casas).  \n",
    "- `y = boston.iloc[:, -1]` ‚Üí la √∫ltima columna (precio medio de la vivienda).\n",
    "\n",
    "| Caracter√≠sticas (X)        | Objetivo (y)      |\n",
    "|-----------------------------|-------------------|\n",
    "| Habitaciones, edad, etc... | Precio de la casa |\n",
    "\n",
    "üëâ **En resumen:** separar en `X` e `y` es necesario porque el modelo aprende una funci√≥n que transforma `X` en una predicci√≥n de `y`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39f2f41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 13) (303,)\n",
      "(203, 13) (203,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.667431382173115"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = boston.iloc[:, :-1]\n",
    "y = boston.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "regression = svm.SVR(kernel='linear', C=1).fit(X_train, y_train)\n",
    "regression.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2dab17",
   "metadata": {},
   "source": [
    "Cuando se eval√∫an diferentes configuraciones (\"hiperpar√°metros\") para estimadores, como el par√°metro `C` que debe establecerse manualmente para un SVM, a√∫n existe el riesgo de sobreajuste en el conjunto de prueba porque los par√°metros pueden ajustarse hasta que el rendimiento sea √≥ptimo.\n",
    "\n",
    "De esta manera, el conocimiento sobre el conjunto de prueba puede \"filtrarse\" en el modelo y las m√©tricas de evaluaci√≥n ya no informan sobre el rendimiento de generalizaci√≥n.\n",
    "\n",
    "Para resolver este problema, se puede reservar otra parte del conjunto de datos como un llamado \"conjunto de validaci√≥n\": el entrenamiento procede con el conjunto de entrenamiento, despu√©s la evaluaci√≥n se hace con el conjunto de validaci√≥n y, cuando el experimento parece ser exitoso, la evaluaci√≥n final se hace en el conjunto de prueba.\n",
    "\n",
    "Sin embargo, al dividir los datos disponibles en tres conjuntos, reducimos dr√°sticamente el n√∫mero de muestras que se pueden usar para entrenar el modelo, y los resultados pueden depender de una elecci√≥n aleatoria particular para el par de conjuntos (entrenamiento, validaci√≥n).\n",
    "\n",
    "Una soluci√≥n a este problema, como se discuti√≥ antes, es un procedimiento llamado **validaci√≥n cruzada** (abreviado CV). Un conjunto de prueba todav√≠a debe reservarse para la evaluaci√≥n final, pero el conjunto de validaci√≥n ya no es necesario al hacer CV. En el enfoque b√°sico, llamado **validaci√≥n cruzada k-fold**, el conjunto de entrenamiento se divide en k subconjuntos m√°s peque√±os (otros enfoques se describen a continuaci√≥n, pero en general siguen los mismos principios). El procedimiento seguido para cada uno de los k ‚Äúfolds‚Äù es:\n",
    "\n",
    "- Un modelo se entrena usando k-1 de los folds como datos de entrenamiento.  \n",
    "- El modelo resultante se valida en la parte restante de los datos (es decir, se usa como conjunto de prueba para calcular una m√©trica de rendimiento como la exactitud).  \n",
    "\n",
    "La medida de rendimiento reportada por la validaci√≥n cruzada k-fold es entonces el promedio de los valores calculados en el bucle. Este enfoque puede ser computacionalmente costoso, pero no desperdicia tantos datos (como ocurre al fijar arbitrariamente un conjunto de validaci√≥n), lo que es una gran ventaja en problemas como la inferencia inversa, donde el n√∫mero de muestras es muy peque√±o.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c49086",
   "metadata": {},
   "source": [
    "---\n",
    "## COMPUTANDO COSS-VALIDATION METRICAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cb81c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77285459, 0.72771739, 0.56131914, 0.15056451, 0.08212844])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "regression = svm.SVR(kernel='linear', C=1)\n",
    "scores = cross_val_score(regression, X, y, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e673d4",
   "metadata": {},
   "source": [
    "La puntuaci√≥n media y el intervalo de confianza del 95% de la estimaci√≥n de la puntuaci√≥n son, por lo tanto, los siguientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cbdeab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.46 (+/- 0.08)\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f301b1",
   "metadata": {},
   "source": [
    "De forma predeterminada, la puntuaci√≥n calculada en cada iteraci√≥n de la validaci√≥n cruzada es el m√©todo `score` del estimador.  \n",
    "Es posible cambiar esto utilizando el par√°metro `scoring`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa0c2217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -7.84451123, -24.78772444, -35.13272326, -74.50555945,\n",
       "       -24.40465975])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "scores = cross_val_score(regression, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc3dba8",
   "metadata": {},
   "source": [
    "Consulta **The scoring parameter: defining model evaluation rules** para m√°s detalles.  \n",
    "En el caso del conjunto de datos *Iris*, las muestras est√°n equilibradas entre las clases objetivo,  \n",
    "por lo tanto, la exactitud y la puntuaci√≥n F1 son casi iguales.\n",
    "\n",
    "Cuando el argumento `cv` es un n√∫mero entero, `cross_val_score` usa las estrategias **KFold** o **StratifiedKFold** por defecto,  \n",
    "siendo esta √∫ltima utilizada si el estimador proviene de `ClassifierMixin`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec713bd",
   "metadata": {},
   "source": [
    "## K-Fold\n",
    "\n",
    "### ¬øQu√© es?\n",
    "**K-Fold Cross Validation** es una t√©cnica de validaci√≥n cruzada donde el conjunto de datos se divide en *k* subconjuntos (llamados *folds*).  \n",
    "El modelo se entrena *k* veces, cada vez usando *k-1* folds para entrenamiento y el fold restante para validaci√≥n.\n",
    "\n",
    "### Procedimiento\n",
    "1. Se divide el dataset en *k* folds de tama√±o similar.  \n",
    "2. En cada iteraci√≥n:\n",
    "   - Se entrena el modelo con *k-1* folds.  \n",
    "   - Se valida con el fold restante.  \n",
    "3. Se repite el proceso *k* veces, cambiando el fold que se deja para validaci√≥n.  \n",
    "4. Se calcula la m√©trica promedio de rendimiento.\n",
    "\n",
    "### Ejemplo (k=5)\n",
    "- Iteraci√≥n 1: folds 1-4 entrenan, fold 5 valida  \n",
    "- Iteraci√≥n 2: folds 1-3 y 5 entrenan, fold 4 valida  \n",
    "- ‚Ä¶  \n",
    "- Iteraci√≥n 5: folds 2-5 entrenan, fold 1 valida  \n",
    "\n",
    "### Ventajas\n",
    "- Utiliza **todo el dataset** tanto para entrenar como para validar (en diferentes momentos).  \n",
    "- Da una evaluaci√≥n m√°s robusta que un simple train/test split.\n",
    "\n",
    "### Desventajas\n",
    "- Puede ser **computacionalmente costoso**, ya que el modelo se entrena *k* veces.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "495f8ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3] [0 1]\n",
      "[0 1] [2 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X = [\"a\",\"b\",\"c\",\"d\"]\n",
    "kf = KFold(n_splits = 2)\n",
    "for train, test in kf.split(X):\n",
    "    print(\"%s %s\" % (train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d30379a",
   "metadata": {},
   "source": [
    "## Stratified K-Fold\n",
    "\n",
    "### ¬øQu√© es?\n",
    "**Stratified K-Fold** es una variante del m√©todo de validaci√≥n cruzada **K-Fold** que se utiliza principalmente en **problemas de clasificaci√≥n**.\n",
    "\n",
    "### Diferencia con K-Fold normal\n",
    "- **K-Fold normal**: divide el dataset en *k* subconjuntos (*folds*) de manera aleatoria, intentando que tengan un tama√±o similar.  \n",
    "- **Stratified K-Fold**: adem√°s de dividir en *k* folds, **mantiene la misma proporci√≥n de clases en cada fold** que en el conjunto de datos original.\n",
    "\n",
    "### Ejemplo\n",
    "Dataset con 100 muestras:\n",
    "- 80 de la clase A  \n",
    "- 20 de la clase B  \n",
    "\n",
    "- Con **K-Fold normal**, algunos *folds* podr√≠an tener muy pocos o incluso ning√∫n ejemplo de la clase B.  \n",
    "- Con **Stratified K-Fold**, cada fold tendr√° aproximadamente un **80% A y 20% B**, igual que el dataset completo.\n",
    "\n",
    "### ¬øPor qu√© es importante?\n",
    "- En datasets **desbalanceados**, el K-Fold normal puede generar evaluaciones poco realistas.  \n",
    "- **Stratified K-Fold** asegura que el modelo se entrene y valide siempre con una representaci√≥n equilibrada de las clases.  \n",
    "\n",
    "### En Scikit-learn\n",
    "Cuando se usa `cross_val_score` con clasificadores (`ClassifierMixin`), por defecto se aplica **StratifiedKFold** en lugar de K-Fold.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f89ba07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 6 7 8 9] [0 1 4 5]\n",
      "[0 1 3 4 5 8 9] [2 6 7]\n",
      "[0 1 2 4 5 6 7] [3 8 9]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "X = np.ones(10)\n",
    "y = [0,0,0,0,1,1,1,1,1,1]\n",
    "skf = StratifiedKFold(n_splits = 3)\n",
    "for train, test in skf.split(X, y):\n",
    "    print(\"%s %s\" % (train, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b764af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.391\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# pipe_lr = make_pipeline(StandardScaler(), PCA(n_components = 2), LogisticRegression(random_state = 1))\n",
    "pipe_svm = make_pipeline(StandardScaler(), PCA(n_components = 2), svm.SVR(kernel = 'linear', C = 1))\n",
    "\n",
    "pipe_svm.fit(X_train, y_train)\n",
    "y_pred = pipe_svm.predict(X_test)\n",
    "print('Test accuracy: %.3f' % pipe_svm.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e076db00",
   "metadata": {},
   "source": [
    "## Pipeline con PCA y SVM (Scikit-learn)\n",
    "\n",
    "### ¬øQu√© hace este c√≥digo?\n",
    "1. **Escala los datos** con `StandardScaler` (media 0, varianza 1).  \n",
    "2. **Reduce la dimensionalidad** con `PCA(n_components=2)`.  \n",
    "3. **Entrena un modelo SVM de regresi√≥n** (`SVR`) con kernel lineal y `C=1`.  \n",
    "4. **Eval√∫a el rendimiento** en un conjunto de prueba.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f15144a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores: [0.63971176 0.43579197 0.46977821 0.25027246 0.5124364  0.26221374\n",
      " 0.30877195 0.54528563 0.37810066 0.47313549]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(estimator = pipe_svm, X = X_train, y = y_train, cv = 10, n_jobs = 1)\n",
    "print('CV accuracy scores: %s' % scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ceddc72",
   "metadata": {},
   "source": [
    "## Validaci√≥n cruzada con cross_val_score\n",
    "\n",
    "### Descripci√≥n\n",
    "Este fragmento aplica **validaci√≥n cruzada** usando la funci√≥n `cross_val_score` de Scikit-learn.  \n",
    "El objetivo es evaluar el rendimiento del modelo de manera m√°s robusta que con un simple train/test split.\n",
    "\n",
    "### Paso a paso\n",
    "1. **Importaci√≥n**  \n",
    "   Se utiliza la funci√≥n `cross_val_score` para automatizar la validaci√≥n cruzada.\n",
    "\n",
    "2. **Ejecuci√≥n**  \n",
    "   - El modelo `pipe_svm` se entrena y valida mediante **10 folds** (particiones).  \n",
    "   - En cada iteraci√≥n, el modelo se entrena con 9 folds y se valida con el fold restante.  \n",
    "   - El resultado es una lista con las m√©tricas obtenidas en cada fold.\n",
    "\n",
    "3. **Par√°metros principales**  \n",
    "   - **estimator = pipe_svm** ‚Üí el pipeline con escalado, PCA y SVM.  \n",
    "   - **X = X_train, y = y_train** ‚Üí datos de entrenamiento y sus etiquetas.  \n",
    "   - **cv = 10** ‚Üí n√∫mero de folds en la validaci√≥n cruzada.  \n",
    "   - **n_jobs = 1** ‚Üí n√∫mero de n√∫cleos de CPU utilizados (1 = secuencial).\n",
    "\n",
    "4. **Salida**  \n",
    "   - Se imprimen los puntajes de cada fold (precisi√≥n o R¬≤ dependiendo del tipo de modelo).  \n",
    "   - Estos valores permiten analizar la variabilidad del modelo y detectar si es estable o inestable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b96bfca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy: 0.428 +/- 0.121\n"
     ]
    }
   ],
   "source": [
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dee8caf",
   "metadata": {},
   "source": [
    "## Promedio y desviaci√≥n est√°ndar de la validaci√≥n cruzada\n",
    "\n",
    "### Descripci√≥n\n",
    "Este comando muestra un **resumen del rendimiento del modelo** tras la validaci√≥n cruzada.\n",
    "\n",
    "### Explicaci√≥n\n",
    "- **np.mean(scores)** ‚Üí calcula el promedio de las m√©tricas obtenidas en todos los folds.  \n",
    "  - Representa el **rendimiento medio** del modelo.  \n",
    "- **np.std(scores)** ‚Üí calcula la desviaci√≥n est√°ndar de esas m√©tricas.  \n",
    "  - Indica la **variabilidad o estabilidad** del modelo entre los distintos folds.  \n",
    "\n",
    "### Salida\n",
    "El resultado se imprime en el formato:  \n",
    "**CV accuracy: valor_promedio +/- desviaci√≥n**  \n",
    "\n",
    "Ejemplo:  \n",
    "`CV accuracy: 0.428 +/- 0.121`  \n",
    "- **0.428** ‚Üí rendimiento medio del modelo.  \n",
    "- **0.121** ‚Üí dispersi√≥n de los resultados; cuanto menor sea, m√°s estable es el modelo.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
